_wandb:
    value:
        cli_version: 0.20.1
        m:
            - "1": trainer/global_step
              "6":
                - 3
              "7": []
            - "1": prediction_plot_0.format
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_0.height
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_0._type
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_1.size
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_2.height
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_3.size
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_3.path
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": train_loss_step
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_2.sha256
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_3.width
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_4.sha256
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_attention._type
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_4.height
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_static_variables.size
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": lr-AdamW
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": val_SMAPE
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_2.size
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_2.path
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": train_loss_epoch
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_0.path
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_attention.sha256
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_1.format
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_static_variables.height
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_0.size
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_1.sha256
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_4._type
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_static_variables.sha256
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_encoder_variables.path
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": val_RMSE
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_2.width
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_static_variables.format
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_encoder_variables._type
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_decoder_variables.path
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_2.format
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_3.format
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_encoder_variables.format
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_encoder_variables.width
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_encoder_variables.height
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_3.height
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_4.path
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_attention.format
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_attention.size
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_decoder_variables.format
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_decoder_variables.height
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": val_MAE
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_1.height
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_3._type
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_4.size
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_4.width
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_attention.height
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_attention.path
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_encoder_variables.size
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_0.width
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_attention.width
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_static_variables.path
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_decoder_variables.width
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_decoder_variables.size
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_1.path
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_decoder_variables._type
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_decoder_variables.sha256
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": epoch
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_0.sha256
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_3.sha256
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_4.format
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_static_variables.width
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_encoder_variables.sha256
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": val_loss
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": val_MAPE
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_1.width
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_1._type
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": prediction_plot_2._type
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": variable_importance_static_variables._type
              "5": 1
              "6":
                - 1
                - 3
              "7": []
        python_version: 3.12.7
        t:
            "1":
                - 1
                - 5
                - 53
                - 106
            "2":
                - 1
                - 2
                - 3
                - 5
                - 9
                - 53
                - 103
                - 106
            "3":
                - 7
                - 13
                - 16
                - 55
                - 66
            "4": 3.12.7
            "5": 0.20.1
            "8":
                - 3
            "12": 0.20.1
            "13": windows-amd64
accelerator:
    value: gpu
accumulate_grad_batches:
    value: 1
attention_head_size:
    value: 8
batch_size:
    value: 256
cache_dir:
    value: data_cache
causal_attention:
    value: true
data_path:
    value: raw_data_4k.csv
dataset_parameters:
    value:
        add_encoder_length: true
        add_relative_time_idx: false
        add_target_scales: false
        allow_missing_timesteps: true
        categorical_encoders:
            __group_id__Ticker: NaNLabelEncoder(add_nan=False, warn=True)
            sic_sector: NaNLabelEncoder(add_nan=False, warn=True)
        constant_fill_strategy: null
        group_ids:
            - Ticker
        lags: null
        max_encoder_length: 30
        max_prediction_length: 3
        min_encoder_length: 15
        min_prediction_idx: 0
        min_prediction_length: 3
        predict_mode: false
        randomize_length: null
        scalers:
            adx_7: StandardScaler()
            atr_5: StandardScaler()
            bb_width_10: StandardScaler()
            buzz_score_T0: StandardScaler()
            day_of_week: StandardScaler()
            dollar_vol_z: StandardScaler()
            ema_fast5_slow10: StandardScaler()
            encoder_length: StandardScaler()
            log_ret_1: StandardScaler()
            log_ret_2: StandardScaler()
            log_ret_3: StandardScaler()
            macd_fast5_slow13: StandardScaler()
            mfi_5: StandardScaler()
            neg_ratio_T0: StandardScaler()
            obv: StandardScaler()
            pos_ratio_T0: StandardScaler()
            real_vol_5: StandardScaler()
            rsi_3: StandardScaler()
            rsi_7: StandardScaler()
            sent_count_T0: StandardScaler()
            sent_mean_T0: StandardScaler()
            sent_sum_3d: StandardScaler()
            sent_vol_T0: StandardScaler()
            sma_5_close: StandardScaler()
            stoch_d_5: StandardScaler()
            stoch_k_5: StandardScaler()
            williams_r_7: StandardScaler()
        static_categoricals:
            - sic_sector
        static_reals: []
        target: Close
        target_normalizer: |-
            EncoderNormalizer(
            	method='standard',
            	center=True,
            	max_length=None,
            	transformation='log',
            	method_kwargs={}
            )
        time_idx: time_idx
        time_varying_known_categoricals: null
        time_varying_known_reals:
            - day_of_week
            - sent_count_T0
            - sent_mean_T0
            - sent_vol_T0
            - sent_sum_3d
            - buzz_score_T0
            - pos_ratio_T0
            - neg_ratio_T0
            - atr_5
            - log_ret_1
            - log_ret_2
            - log_ret_3
        time_varying_unknown_categoricals: null
        time_varying_unknown_reals:
            - sma_5_close
            - ema_fast5_slow10
            - rsi_3
            - rsi_7
            - macd_fast5_slow13
            - bb_width_10
            - real_vol_5
            - obv
            - mfi_5
            - dollar_vol_z
            - stoch_k_5
            - stoch_d_5
            - adx_7
            - williams_r_7
        variable_groups: null
        weight: null
dropout:
    value: 0.12
early_stopping:
    value: true
early_stopping_min_delta:
    value: 1e-05
early_stopping_patience:
    value: 15
embedding_labels:
    value:
        sic_sector:
            Communication: 0
            Consumer_Discretionary: 1
            Consumer_Staples: 2
            Energy: 3
            Financial: 4
            Healthcare: 5
            Industrials: 6
            Materials: 7
            Other: 8
            Real_Estate: 9
            Technology: 10
            Unknown: 11
            Utilities: 12
embedding_paddings:
    value: []
embedding_sizes:
    value:
        sic_sector:
            - 13
            - 7
epochs:
    value: 30
experiment_name:
    value: tft_20250628_122613_6d872b
experiment_notes:
    value: ' Testing Sector Mixture-of-Experts (MOE) with gated heads per SIC sector code such that each sector owns its own linear projection and bias'
expert_dropout:
    value: 0.1
expert_hidden_size:
    value: 64
gradient_clip:
    value: 0.1
hidden_continuous_size:
    value: 160
hidden_size:
    value: 192
learning_rate:
    value: 0.002
log_gradient_flow:
    value: false
log_interval:
    value: -1
log_val_interval:
    value: null
lstm_layers:
    value: 2
mask_bias:
    value: -1e+09
max_encoder_length:
    value: 30
max_prediction_length:
    value: 3
mlflow_experiment:
    value: tft-quant
mlflow_uri:
    value: azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/6d500bb9-25c2-4821-a253-a860046398df/resourceGroups/Project_DeepGreen/providers/Microsoft.MachineLearningServices/workspaces/DeepGreen
notes:
    value: ' Testing Sector Mixture-of-Experts (MOE) with gated heads per SIC sector code such that each sector owns its own linear projection and bias'
num_prediction_plots:
    value: 5
onnx_model_name:
    value: tft_20250628_122613_6d872b_fp8.onnx
optimizer:
    value: adamw
optimizer_params:
    value: null
output_size:
    value: 7
output_transformer:
    value: null
precision:
    value: bf16-mixed
prediction_window:
    value: 3
reduce_on_plateau_min_lr:
    value: 1e-05
reduce_on_plateau_patience:
    value: 5
reduce_on_plateau_reduction:
    value: 2
share_single_variable_networks:
    value: false
static_categoricals:
    value:
        - sic_sector
static_reals:
    value:
        - encoder_length
time_varying_categoricals_decoder:
    value: []
time_varying_categoricals_encoder:
    value: []
time_varying_reals_decoder:
    value:
        - day_of_week
        - sent_count_T0
        - sent_mean_T0
        - sent_vol_T0
        - sent_sum_3d
        - buzz_score_T0
        - pos_ratio_T0
        - neg_ratio_T0
        - atr_5
        - log_ret_1
        - log_ret_2
        - log_ret_3
time_varying_reals_encoder:
    value:
        - day_of_week
        - sent_count_T0
        - sent_mean_T0
        - sent_vol_T0
        - sent_sum_3d
        - buzz_score_T0
        - pos_ratio_T0
        - neg_ratio_T0
        - atr_5
        - log_ret_1
        - log_ret_2
        - log_ret_3
        - sma_5_close
        - ema_fast5_slow10
        - rsi_3
        - rsi_7
        - macd_fast5_slow13
        - bb_width_10
        - real_vol_5
        - obv
        - mfi_5
        - dollar_vol_z
        - stoch_k_5
        - stoch_d_5
        - adx_7
        - williams_r_7
use_cache:
    value: true
use_mixture_of_experts:
    value: false
use_mlflow:
    value: true
use_wandb:
    value: true
val_check_interval:
    value: 0.25
wandb_project:
    value: tft-us-equities
weight_decay:
    value: 0.01
x_categoricals:
    value:
        - sic_sector
x_reals:
    value:
        - encoder_length
        - day_of_week
        - sent_count_T0
        - sent_mean_T0
        - sent_vol_T0
        - sent_sum_3d
        - buzz_score_T0
        - pos_ratio_T0
        - neg_ratio_T0
        - atr_5
        - log_ret_1
        - log_ret_2
        - log_ret_3
        - sma_5_close
        - ema_fast5_slow10
        - rsi_3
        - rsi_7
        - macd_fast5_slow13
        - bb_width_10
        - real_vol_5
        - obv
        - mfi_5
        - dollar_vol_z
        - stoch_k_5
        - stoch_d_5
        - adx_7
        - williams_r_7
years:
    value: 5
